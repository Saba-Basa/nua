
[Data responsibility]

Decide which variables are relevant predictors and which variable is the target, 
excluding irrelevant or confounding information.

In predictive modeling, expert knowledge is needed to choose relevant data, 
because irrelevant or confounding information can weaken the predictive signal and harm model performance.
(Kuhn & Johnson, Applied Predictive Modeling, 2013, Ch. 1.2)

[Notation]
- X : all predictors (features), shape (n, P)
    X  (NumPy array / pandas DataFrame)

- y : target / response, length n
    y  (1D array / Series)

- x_ij : value of feature j for sample i
    X[i, j] or X.iloc[i, j]

- x_i : feature vector for sample i (row i of X)
    code: X[i, :] or X.iloc[i, :]

- n : number of samples (rows)
- P : number of features (columns)

(Kuhn & Johnson – Applied Predictive Modeling, Ch. 1.6 “Notation”)

[PREDICTIVE MODELING PROCESS]

Major Question:
How do we correctly transform raw data into a model that generalizes?

Pipeline (fixed order, no deviations):

1. Data Understanding
   - What is the prediction objective?
   Definition:
    "The predictors, independent variables, attributes, 
    or descriptors are the data used as input for the prediction equation."
    (Kuhn & Johnson, Applied Predictive Modeling, 2013, Ch. 1.3)
    - the input data
    Function:
    - represent the input data
    Condition:
    It applies when a predictive model is constructed or used to generate predictions
    for example:
    when computing ^y(target) from X (all predictors: features).
    Design reason:
    Why is this concept structured this way?
    - to separate inputs from the quantity being predicted
    - so the model can learn a mapping X->y
    (fitting a function from inputs to 
    outputs under an error criterion)
    Boundary:
    they're seperate to what?.
    Predictors must not include or encode the target.
    the target is the output.


   - What is X (predictors)?
   - What is y (target)?
   - What relationships or patterns are visible?
   - What problems are visible (nonlinearity, extremes, gaps)?

2. Preprocessing
   - What must be cleaned or transformed before modeling?
   - What preprocessing is suggested by data characteristics?
   - What must be done BEFORE any model is built?

3. Data Splitting
   - What data is used for training?
   - What data is used for evaluation?
   - Why is this split appropriate for the prediction goal?
   - What must NOT be reused during training?

4. Model Building
   - What candidate model forms are considered?
   - What assumptions do they encode?
   - What parameters are estimated from training data?

5. Model Evaluation
   - What metric evaluates performance?
   - How is overfitting avoided?
   - What resampling strategy is used?

6. Model Selection
   - Which models are compared?
   - On what evidence is one chosen?
   - What risks remain after selection?
